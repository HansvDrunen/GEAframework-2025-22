{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"5Cap8uTeyFq0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1769027721980,"user_tz":-60,"elapsed":54358,"user":{"displayName":"kailen bernardo","userId":"09171371274025445181"}},"outputId":"83146139-674b-4404-c19b-3307e4c0f646"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.7/80.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m360.5/360.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["#install dependencies\n","!pip install -q sentence-transformers transformers torch yake openpyxl\n","!pip install -q yake\n","!pip install -q sentence-transformers yake\n","!pip install -q tqdm\n","!pip install -q xlsxwriter\n","\n"]},{"cell_type":"code","source":["#  Imports\n","import pandas as pd\n","import numpy as np\n","import torch\n","from sentence_transformers import SentenceTransformer, util\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","import yake\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tqdm.notebook import tqdm\n"],"metadata":{"id":"d_KG9xcfyJcE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1769027775633,"user_tz":-60,"elapsed":53629,"user":{"displayName":"kailen bernardo","userId":"09171371274025445181"}},"outputId":"d17c25f4-d4d5-42f1-f81f-6bb11f2a6461"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"]}]},{"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"id":"O8nJ3OPBzMfm","outputId":"93bb62f5-9479-4719-a7af-b9b3b11182bd","executionInfo":{"status":"ok","timestamp":1769030521024,"user_tz":-60,"elapsed":2745380,"user":{"displayName":"kailen bernardo","userId":"09171371274025445181"}}},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-620414dd-e457-48a7-bd18-a39b342b6c65\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-620414dd-e457-48a7-bd18-a39b342b6c65\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving gea_statements.xlsx to gea_statements.xlsx\n"]}]},{"cell_type":"code","source":["# load data\n","df = pd.read_excel(\"/content/gea_statements.xlsx\")\n","\n","# clean type column (strip spaces, lowercase)\n","df['Type'] = df['Type'].str.strip().str.lower()\n","\n","# fix common typos\n","df['Type'] = df['Type'].replace({\n","    'core alue': 'core value',\n","    'steategy': 'strategy',\n","    'goals': 'goal'\n","})\n","\n","# create lists\n","missions   = df.loc[df['Type'] == 'mission', 'Statement'].dropna().tolist()\n","visions    = df.loc[df['Type'] == 'vision', 'Statement'].dropna().tolist()\n","values     = df.loc[df['Type'] == 'core value', 'Statement'].dropna().tolist()\n","goals      = df.loc[df['Type'] == 'goal', 'Statement'].dropna().tolist()\n","strategies = df.loc[df['Type'] == 'strategy', 'Statement'].dropna().tolist()\n","\n","print(\"Loaded:\")\n","print(\"Missions:\", len(missions))\n","print(\"Visions:\", len(visions))\n","print(\"Values:\", len(values))\n","print(\"Goals:\", len(goals))\n","print(\"Strategies:\", len(strategies))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":547},"id":"pqBRQjd4yNz-","outputId":"aaccf87d-d26e-4dbb-e3ec-21b106d7eb4e","executionInfo":{"status":"error","timestamp":1769030654863,"user_tz":-60,"elapsed":847,"user":{"displayName":"kailen bernardo","userId":"09171371274025445181"}}},"execution_count":5,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"'Type'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Type'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-189633665.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# clean type column (strip spaces, lowercase)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# fix common typos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Type'"]}]},{"cell_type":"code","source":["# embeddings\n","EMB_MODEL_NAME = \"all-mpnet-base-v2\"\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","emb_model = SentenceTransformer(EMB_MODEL_NAME, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","def embed(texts):\n","    if isinstance(texts, str):\n","        texts = [texts]\n","    return emb_model.encode(texts, normalize_embeddings=True, batch_size=32, show_progress_bar=False)"],"metadata":{"id":"gANbkKNyyRWB","executionInfo":{"status":"aborted","timestamp":1769030521073,"user_tz":-60,"elapsed":2853618,"user":{"displayName":"kailen bernardo","userId":"09171371274025445181"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#  NLI / entailment\n","NLI_MODEL = \"roberta-large-mnli\"\n","tok = AutoTokenizer.from_pretrained(NLI_MODEL)\n","nli = AutoModelForSequenceClassification.from_pretrained(NLI_MODEL)\n","nli.eval()\n","CONTR_IDX, NEUTRAL_IDX, ENTAIL_IDX = 0, 1, 2\n","\n","@torch.inference_mode()\n","def nli_probs(premises, hypotheses, batch_size=16):\n","    device = next(nli.parameters()).device\n","    c_all, n_all, e_all = [], [], []\n","    for i in range(0, len(premises), batch_size):\n","        p = premises[i:i+batch_size]\n","        h = hypotheses[i:i+batch_size]\n","        enc = tok(p, h, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n","        logits = nli(**enc).logits\n","        probs = torch.softmax(logits, dim=-1).detach().cpu().numpy()\n","        c_all.append(probs[:, CONTR_IDX])\n","        n_all.append(probs[:, NEUTRAL_IDX])\n","        e_all.append(probs[:, ENTAIL_IDX])\n","    return np.concatenate(c_all), np.concatenate(n_all), np.concatenate(e_all)\n","\n"],"metadata":{"id":"w7VDUd03yUU6","executionInfo":{"status":"aborted","timestamp":1769030521075,"user_tz":-60,"elapsed":2853616,"user":{"displayName":"kailen bernardo","userId":"09171371274025445181"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# keyword extraction using YAKE\n","def extract_keywords(text, max_keywords=5):\n","    kw_extractor = yake.KeywordExtractor(lan=\"en\", n=3, top=max_keywords)\n","    keywords = kw_extractor.extract_keywords(text)\n","    return [kw for kw, score in keywords] or [text]\n"],"metadata":{"id":"SUn_SLtvyWbA","executionInfo":{"status":"aborted","timestamp":1769030521112,"user_tz":-60,"elapsed":2853651,"user":{"displayName":"kailen bernardo","userId":"09171371274025445181"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# precompute embeddings & keywords for speed\n","def precompute_embeddings(texts, use_keywords=False, max_kw=5):\n","    \"\"\"\n","    Returns:\n","        items: list[str or list[str]]  -> text or keywords\n","        embeddings: list[np.array]    -> embeddings for each text/keyword\n","    \"\"\"\n","    items = []\n","    embeddings = []\n","\n","    for t in texts:\n","        # extract keywords if requested\n","        if use_keywords:\n","            kws = extract_keywords(t, max_keywords=max_kw)\n","            if not kws:\n","                kws = [t]  # fallback to full text\n","        else:\n","            kws = [t]\n","\n","        items.append(kws)\n","\n","        # embed each keyword and take mean for multi-keyword entries\n","        kw_embs = embed(kws)\n","        mean_emb = np.mean(kw_embs, axis=0)\n","        embeddings.append(mean_emb)\n","\n","    return items, embeddings\n","\n","# optimized scoring using precomputed embeddings\n","def build_matrix_fast(rows, cols, use_keywords=False, max_kw=5):\n","    # precompute embeddings\n","    rows_items, rows_embs = precompute_embeddings(rows, use_keywords=False)\n","    cols_items, cols_embs = precompute_embeddings(cols, use_keywords=use_keywords, max_kw=max_kw)\n","\n","    mat = []\n","    debug_rows = []\n","\n","    for i, r_emb in enumerate(rows_embs):\n","        row_scores = []\n","        for j, c_emb in enumerate(cols_embs):\n","            # cosine similarity\n","            sim = float(np.dot(r_emb, c_emb))\n","\n","            # NLI on full texts (for more precision, you can also do batch NLI)\n","            c, n, e = nli_probs([rows[i]], [cols[j]])\n","            c, n, e = float(c[0]), float(n[0]), float(e[0])\n","\n","            # apply scoring rules\n","            if c >= 0.60 and sim >= 0.20: score = -2\n","            elif c >= 0.40 and sim >= 0.20: score = -1\n","            elif sim >= 0.55: score = 3\n","            elif sim >= 0.42: score = 2\n","            elif sim >= 0.22: score = 1\n","            else: score = 0\n","\n","            row_scores.append(score)\n","            debug_rows.append({\n","                \"premise\": rows[i],\n","                \"hypothesis\": cols[j],\n","                \"score\": score,\n","                \"keywords\": cols_items[j]\n","            })\n","\n","        mat.append(row_scores)\n","\n","    df_matrix = pd.DataFrame(mat, columns=cols)\n","    df_matrix.insert(0, \"Premise\", rows)\n","    df_debug = pd.DataFrame(debug_rows)\n","    return df_matrix, df_debug\n"],"metadata":{"id":"NX-91NTKyX8J","executionInfo":{"status":"aborted","timestamp":1769030521114,"user_tz":-60,"elapsed":2853652,"user":{"displayName":"kailen bernardo","userId":"09171371274025445181"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# scoring pairs\n","def score_pair(premise, hypothesis):\n","    s_vec = embed(premise)[0]\n","    h_vec = embed(hypothesis)[0]\n","    sim = float(np.dot(s_vec, h_vec))  # cosine similarity, embeddings normalized\n","\n","    c, n, e = nli_probs([premise], [hypothesis])\n","    c, n, e = float(c[0]), float(n[0]), float(e[0])\n","\n","    # scoring rules\n","    if c >= 0.60 and sim >= 0.20: return -2, sim, c, n, e\n","    if c >= 0.40 and sim >= 0.20: return -1, sim, c, n, e\n","    if sim >= 0.55: return 3, sim, c, n, e\n","    if sim >= 0.42: return 2, sim, c, n, e\n","    if sim >= 0.22: return 1, sim, c, n, e\n","    return 0, sim, c, n, e\n"],"metadata":{"id":"GxrAyrFAyZ8i","executionInfo":{"status":"aborted","timestamp":1769030521115,"user_tz":-60,"elapsed":2853653,"user":{"displayName":"kailen bernardo","userId":"09171371274025445181"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plot matrix\n","def plot_matrix(df_matrix, title=\"Coherence Matrix\"):\n","    plt.figure(figsize=(10,6))\n","    sns.heatmap(df_matrix.iloc[:,1:], annot=True, fmt=\"d\", cmap=\"coolwarm\", cbar=True)\n","    plt.title(title)\n","    plt.ylabel(\"Premise\")\n","    plt.xlabel(\"Hypothesis\")\n","    plt.show()\n"],"metadata":{"id":"5Lf2ETnSyeqG","executionInfo":{"status":"aborted","timestamp":1769030521116,"user_tz":-60,"elapsed":2853653,"user":{"displayName":"kailen bernardo","userId":"09171371274025445181"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tqdm.notebook import tqdm\n","\n","matrices = {}\n","\n","companies = df['Company'].unique()[:4]  # only first 4 companies\n","\n","for company in tqdm(companies, desc=\"Processing first 4 companies\"):\n","    df_c = df[df['Company'] == company]\n","\n","    missions   = df_c.loc[df_c['Type'] == 'mission', 'Statement'].dropna().tolist()\n","    visions    = df_c.loc[df_c['Type'] == 'vision', 'Statement'].dropna().tolist()\n","    values     = df_c.loc[df_c['Type'] == 'core value', 'Statement'].dropna().tolist()\n","    goals      = df_c.loc[df_c['Type'] == 'goal', 'Statement'].dropna().tolist()\n","    strategies = df_c.loc[df_c['Type'] == 'strategy', 'Statement'].dropna().tolist()\n","\n","    if len(missions)==0 and len(visions)==0 and len(values)==0 and len(goals)==0:\n","        continue  # skip empty companies\n","\n","    matrices[company] = {}\n","\n","    # build matrices per company\n","    matrices[company]['Mission_vs_Vision'] = build_matrix_fast(missions, visions, use_keywords=True)\n","    # matrices[company]['Vision_vs_Mission'] = build_matrix_fast(visions, missions, use_keywords=True)\n","    matrices[company]['Values_vs_Mission'] = build_matrix_fast(values, missions, use_keywords=False)\n","    matrices[company]['Values_vs_Vision'] = build_matrix_fast(values, visions, use_keywords=False)\n","    matrices[company]['Goals_vs_Mission'] = build_matrix_fast(goals, missions, use_keywords=False)\n","    matrices[company]['Goals_vs_Vision'] = build_matrix_fast(goals, visions, use_keywords=False)\n","    matrices[company]['Goals_vs_Strategy'] = build_matrix_fast(goals, strategies, use_keywords=False)\n"],"metadata":{"id":"uq55C9wHyhlE","executionInfo":{"status":"aborted","timestamp":1769030521117,"user_tz":-60,"elapsed":2853651,"user":{"displayName":"kailen bernardo","userId":"09171371274025445181"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from IPython.display import display\n","import ipywidgets as widgets\n","import os\n","\n","\n","# function to save matrices per company\n","\n","def save_company_matrices(matrices_dict, folder=\"company_excels\"):\n","    \"\"\"\n","    Save each company's matrices to a separate Excel file.\n","    Returns dict of filenames.\n","    \"\"\"\n","    if not os.path.exists(folder):\n","        os.makedirs(folder)\n","\n","    saved_files = {}\n","\n","    for company, comps_matrices in matrices_dict.items():\n","        filename = f\"{folder}/{company.replace(' ','_')}_matrices.xlsx\"\n","        with pd.ExcelWriter(filename, engine='xlsxwriter') as writer:\n","            for name, (df_matrix, df_debug) in comps_matrices.items():\n","                df_matrix.to_excel(writer, sheet_name=name[:31], index=False)\n","        saved_files[company] = filename\n","\n","    return saved_files\n","\n","# function to create download buttons\n","\n","def create_download_buttons(saved_files):\n","    \"\"\"\n","    Create clickable download buttons in Colab for each file.\n","    \"\"\"\n","    for company, file_path in saved_files.items():\n","        button = widgets.Button(description=f\"Download {company}\")\n","        output = widgets.Output()\n","\n","        def on_button_clicked(b, path=file_path):\n","            with output:\n","                files.download(path)\n","\n","        button.on_click(on_button_clicked)\n","        display(button, output)\n","\n","# save & create buttons\n","\n","saved_files = save_company_matrices(matrices)\n","create_download_buttons(saved_files)\n","\n","\n","for company, company_matrices in matrices.items():\n","    print(f\"\\n=== {company} ===\")\n","    for matrix_name, (df_matrix, df_debug) in company_matrices.items():\n","        print(f\"\\n--- {matrix_name} ---\")\n","        display(df_matrix)\n","        # plot_matrix(df_matrix, title=f\"{company} - {matrix_name}\")\n","\n","\n"],"metadata":{"id":"EpAiA3cqLNuM","executionInfo":{"status":"aborted","timestamp":1769030521119,"user_tz":-60,"elapsed":2853650,"user":{"displayName":"kailen bernardo","userId":"09171371274025445181"}}},"execution_count":null,"outputs":[]}]}